# Real-time Data Processing and Analysis System with AWS Integration

## Initial Tasks Breakdown

- Setup Kafka Zookeeper Producer Consumer locally. Start off with that by modifying the existing code
- Perform the PySpark analysis locally by chaining the data from the consumer
- Display the results as a log locally
- Create proper documentation to test the idea out and commit the code
(if time permits)
- Push the code to s3 instead of local pyspark
- Push the pyspark to an ec2 instance
- Run the ec2 instance using Lambda + API gateway 

## Flow Diagram

![Architecture Diagram](https://github.com/ashwin-sp/TakeHome/blob/76a492850000365bc3b81b39f1579e458f517565/flow_diagram.png)
